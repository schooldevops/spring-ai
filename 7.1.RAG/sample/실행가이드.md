# RAG 패턴의 이해 샘플 프로젝트 실행 가이드

이 가이드는 7.1.RAG 샘플 프로젝트를 실행하고 테스트하는 방법을 안내합니다.

## 📋 사전 준비사항

- JDK 17 이상 설치
- OpenAI API Key 발급
- 환경 변수 설정 권한

## 🚀 실행 방법

### 1. 환경 변수 설정

**macOS / Linux:**
```bash
export OPENAI_API_KEY="sk-your-api-key-here"
```

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY="sk-your-api-key-here"
```

### 2. 애플리케이션 실행

```bash
./gradlew bootRun
```

또는 IntelliJ IDEA에서 `RAGApplication.kt` 실행

### 3. 실행 확인

애플리케이션이 정상적으로 시작되면 다음과 같은 메시지가 표시됩니다:

```
Started RAGApplication in X.XXX seconds
```

## 🧪 API 테스트

### 1. 샘플 데이터 초기화

RAG 테스트를 위해 샘플 문서를 추가합니다:

```bash
curl -X POST http://localhost:8080/api/demo/init
```

**예상 응답:**
```json
{
  "status": "success",
  "message": "샘플 데이터가 초기화되었습니다.",
  "documentCount": 5
}
```

**추가되는 문서:**
- 환불 정책
- 배송 정책
- 교환 정책
- 회원 혜택
- A/S 정책

### 2. RAG 질문 답변 (POST)

```bash
curl -X POST http://localhost:8080/api/rag/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "환불 정책은 무엇인가요?",
    "topK": 3
  }'
```

**예상 응답:**
```json
{
  "question": "환불 정책은 무엇인가요?",
  "answer": "환불 정책에 따르면 구매 후 7일 이내, 미사용 제품에 한해 환불이 가능합니다...",
  "sources": [
    {
      "content": "환불 정책\n\n구매 후 7일 이내...",
      "metadata": {
        "title": "환불 정책",
        "source": "회사 정책 문서",
        "addedAt": 1234567890
      }
    }
  ],
  "context": "[문서: 환불 정책]\n환불 정책\n\n구매 후 7일 이내..."
}
```

### 3. RAG 질문 답변 (GET)

```bash
curl "http://localhost:8080/api/rag/ask?question=배송%20정책은%20무엇인가요?&topK=3"
```

### 4. 문서 추가

```bash
curl -X POST http://localhost:8080/api/rag/documents \
  -H "Content-Type: application/json" \
  -d '{
    "text": "새로운 정책 내용입니다.",
    "title": "새 정책",
    "source": "정책 문서 v3.0"
  }'
```

### 5. 다양한 질문 테스트

```bash
# 회원 혜택 질문
curl -X POST http://localhost:8080/api/rag/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "회원 혜택은 무엇인가요?", "topK": 2}'

# A/S 정책 질문
curl -X POST http://localhost:8080/api/rag/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "A/S는 어떻게 받나요?", "topK": 2}'

# 교환 정책 질문
curl -X POST http://localhost:8080/api/rag/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "제품 교환이 가능한가요?", "topK": 2}'
```

## 🔍 RAG 동작 확인

### RAG의 4단계 확인

1. **Retrieval (검색)**
   - 질문을 벡터로 변환
   - VectorStore에서 유사한 문서 검색

2. **Augmentation (증강)**
   - 검색된 문서를 Context로 변환
   - 프롬프트에 Context 포함

3. **Generation (생성)**
   - LLM에 Context + 질문 전달
   - LLM이 문서 기반으로 답변 생성

4. **Response (응답)**
   - 답변과 출처 정보 반환

### 응답 구조 확인

```json
{
  "question": "질문",
  "answer": "LLM이 생성한 답변 (문서 기반)",
  "sources": [
    {
      "content": "참조된 문서 내용",
      "metadata": {
        "title": "문서 제목",
        "source": "출처"
      }
    }
  ],
  "context": "LLM에 전달된 전체 Context"
}
```

## 💡 학습 확인

다음 사항을 확인해보세요:

1. **RAG 패턴 이해**
   - 질문 → 검색 → Context 생성 → LLM 호출 → 응답
   - 각 단계의 역할

2. **Grounding 확인**
   - 응답이 실제 문서를 기반으로 생성되는지
   - 출처 정보가 제공되는지

3. **환각 감소 확인**
   - 문서에 없는 내용을 질문했을 때
   - LLM이 "문서에 해당 정보가 없습니다"라고 답변하는지

## ❌ 문제 해결

### 문제 1: 검색 결과가 없음

**증상:**
```
응답이 "관련 문서를 찾을 수 없습니다"로 나옴
```

**해결책:**
1. 샘플 데이터 초기화 확인: `POST /api/demo/init`
2. 문서 추가 확인: `POST /api/rag/documents`
3. 질문 텍스트 확인 (유사한 키워드 사용)

### 문제 2: 답변이 부정확함

**증상:**
```
답변이 문서 내용과 다름
```

**해결책:**
1. topK 값 조정 (더 많은 문서 검색)
2. SystemMessage 개선 (더 명확한 지시)
3. 문서 품질 확인 (명확하고 관련성 높은 문서)

### 문제 3: 응답이 느림

**증상:**
```
질문 답변에 시간이 오래 걸림
```

**해결책:**
1. topK 값 감소 (검색 문서 수 줄이기)
2. Context 길이 제한
3. LLM 모델 변경 (더 빠른 모델 사용)

## ✅ 체크리스트

실행 전 확인사항:

- [ ] JDK 17 이상 설치됨
- [ ] OpenAI API Key 발급됨
- [ ] 환경 변수 설정됨
- [ ] 프로젝트 빌드 성공 (`./gradlew build`)
- [ ] 애플리케이션 실행 성공 (`./gradlew bootRun`)
- [ ] 샘플 데이터 초기화 성공 (`POST /api/demo/init`)
- [ ] RAG 질문 답변 성공 (`POST /api/rag/ask`)

## 🎓 학습 권장 순서

1. **샘플 데이터 초기화**: `POST /api/demo/init`
2. **간단한 질문 테스트**: "환불 정책은 무엇인가요?"
3. **응답 구조 확인**: answer, sources, context 확인
4. **다양한 질문 테스트**: 다른 정책에 대한 질문
5. **문서 추가 테스트**: `POST /api/rag/documents`
6. **코드 분석**: SimpleRAGService.kt 확인

## 📚 핵심 개념 정리

### RAG 패턴

```kotlin
// 1. Retrieval: 관련 문서 검색
val documents = vectorStore.similaritySearch(question) ?: emptyList()
val topK = documents.take(3)

// 2. Augmentation: Context 생성
val context = topK.joinToString("\n\n") { it.text }

// 3. Generation: LLM 호출
val prompt = Prompt(
    listOf(
        SystemMessage("문서를 참고하여 답변해주세요."),
        UserMessage("문서:\n$context\n\n질문: $question")
    )
)
val response = chatModel.call(prompt)

// 4. Response: 답변 반환
val answer = response.results.firstOrNull()?.output?.text ?: ""
```

### Grounding

- **문서 기반 응답**: 실제 문서를 참조하여 답변
- **출처 제공**: 어떤 문서를 참조했는지 명시
- **검증 가능**: 응답의 정확성을 문서로 확인

### Context의 역할

- **배경 지식 제공**: LLM에게 필요한 정보 제공
- **정확성 향상**: 문서 기반으로 정확한 답변 생성
- **환각 감소**: 추측이 아닌 실제 데이터 기반 응답

---

**다음 학습**: [7.2: 간단한 RAG 파이프라인 구현](../../README.md#72-간단한-rag-파이프라인-구현)

