# 22. ChatModel API

## ğŸ“– í•™ìŠµ ëª©í‘œ

ì´ ê°•ì˜ë¥¼ ë§ˆì¹œ í›„ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **ChatModel** ì¸í„°í˜ì´ìŠ¤ì˜ ê°œë…ê³¼ ì‚¬ìš©ë²•ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **StreamingChatModel**ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **Message** íƒ€ì…ë“¤ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ChatOptions**ë¥¼ ì„¤ì •í•˜ì—¬ AI ëª¨ë¸ì˜ ë™ì‘ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ChatResponse**ì™€ **Generation** êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ë©”íƒ€ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

## ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ

1. **ChatModel** - AI ëª¨ë¸ê³¼ í†µì‹ í•˜ëŠ” í•µì‹¬ ì¸í„°í˜ì´ìŠ¤
2. **StreamingChatModel** - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤
3. **Prompt** - ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì™€ ì˜µì…˜ì„ ìº¡ìŠí™”í•˜ëŠ” ìš”ì²­ ê°ì²´
4. **Message** - UserMessage, SystemMessage, AssistantMessage ë“±
5. **ChatOptions** - Temperature, MaxTokens ë“± ëª¨ë¸ ì˜µì…˜
6. **ChatResponse** - AI ëª¨ë¸ì˜ ì‘ë‹µ ê°ì²´
7. **Generation** - ê°œë³„ ì‘ë‹µ ìƒì„± ê²°ê³¼

---

## 1. ChatModel API ê°œìš”

### 1.1 ChatModelì´ë€?

**ChatModel**ì€ Spring AIì—ì„œ AI ëª¨ë¸ê³¼ í†µì‹ í•˜ê¸° ìœ„í•œ í•µì‹¬ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. ChatClientë³´ë‹¤ ë” ì €ìˆ˜ì¤€ì˜ APIë¡œ, ë” ë§ì€ ì œì–´ê¶Œì„ ì œê³µí•©ë‹ˆë‹¤.

```kotlin
interface ChatModel {
    fun call(message: String): String
    fun call(prompt: Prompt): ChatResponse
}
```

### 1.2 ChatModel vs ChatClient

| íŠ¹ì§• | ChatModel | ChatClient |
|------|-----------|------------|
| **ì¶”ìƒí™” ìˆ˜ì¤€** | ë‚®ìŒ (ì €ìˆ˜ì¤€) | ë†’ìŒ (ê³ ìˆ˜ì¤€) |
| **API ìŠ¤íƒ€ì¼** | ëª…ì‹œì  | Fluent |
| **ì œì–´ ìˆ˜ì¤€** | ë†’ìŒ | ì¤‘ê°„ |
| **ì‚¬ìš© í¸ì˜ì„±** | ì¤‘ê°„ | ë†’ìŒ |
| **ê¶Œì¥ ì‚¬ìš©** | ì„¸ë°€í•œ ì œì–´ í•„ìš” ì‹œ | ì¼ë°˜ì ì¸ ì‚¬ìš© |

---

## 2. ìƒ˜í”Œ êµ¬ì„±

### Sample 01: Basic ChatModel Usage
**í•™ìŠµ ë‚´ìš©:**
- ChatModel ì¸í„°í˜ì´ìŠ¤ ê¸°ë³¸ ì‚¬ìš©ë²•
- `call(String)` ê°„ë‹¨í•œ í˜¸ì¶œ
- `call(Prompt)` ìƒì„¸ í˜¸ì¶œ
- ChatResponse êµ¬ì¡° ì´í•´

**ë””ë ‰í† ë¦¬:** [sample01-basic-chatmodel](./sample01-basic-chatmodel/)

---

### Sample 02: StreamingChatModel
**í•™ìŠµ ë‚´ìš©:**
- StreamingChatModel ì¸í„°í˜ì´ìŠ¤
- `stream(String)` ë©”ì„œë“œ
- `stream(Prompt)` ë©”ì„œë“œ
- Flux<String>ê³¼ Flux<ChatResponse> ì²˜ë¦¬

**ë””ë ‰í† ë¦¬:** [sample02-streaming](./sample02-streaming/)

---

### Sample 03: Messages and Prompt
**í•™ìŠµ ë‚´ìš©:**
- Message ì¸í„°í˜ì´ìŠ¤ì™€ êµ¬í˜„ì²´ë“¤
- UserMessage, SystemMessage, AssistantMessage
- Prompt êµ¬ì„± ë°©ë²•
- Message ë©”íƒ€ë°ì´í„°

**ë””ë ‰í† ë¦¬:** [sample03-messages-prompt](./sample03-messages-prompt/)

---

### Sample 04: ChatOptions
**í•™ìŠµ ë‚´ìš©:**
- ChatOptions ì¸í„°í˜ì´ìŠ¤
- Temperature, MaxTokens, TopP ì„¤ì •
- ëª¨ë¸ë³„ íŠ¹í™” ì˜µì…˜
- Promptì— ì˜µì…˜ ì ìš©

**ë””ë ‰í† ë¦¬:** [sample04-chat-options](./sample04-chat-options/)

---

### Sample 05: ChatResponse and Generation
**í•™ìŠµ ë‚´ìš©:**
- ChatResponse êµ¬ì¡° ìƒì„¸
- Generation ê°ì²´ ì ‘ê·¼
- Usage ë©”íƒ€ë°ì´í„° (í† í° ì‚¬ìš©ëŸ‰)
- Finish Reason ì´í•´

**ë””ë ‰í† ë¦¬:** [sample05-chatresponse-generation](./sample05-chatresponse-generation/)

---

## 3. ê³µí†µ ì„¤ì •

### í•„ìˆ˜ ì˜ì¡´ì„±

```kotlin
dependencies {
    implementation("org.springframework.boot:spring-boot-starter-web")
    implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter")
    implementation("com.fasterxml.jackson.module:jackson-module-kotlin")
    implementation("org.jetbrains.kotlin:kotlin-reflect")
    
    testImplementation("org.springframework.boot:spring-boot-starter-test")
    testImplementation("io.projectreactor:reactor-test")
}
```

### application.yml

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.7
```

---

## 4. ì£¼ìš” ì¸í„°í˜ì´ìŠ¤

### ChatModel

```kotlin
val chatModel: ChatModel

// ê°„ë‹¨í•œ í˜¸ì¶œ
val response: String = chatModel.call("Your question")

// ìƒì„¸ í˜¸ì¶œ
val prompt = Prompt("Your question")
val chatResponse: ChatResponse = chatModel.call(prompt)
```

### StreamingChatModel

```kotlin
val chatModel: ChatModel  // ChatModelì€ StreamingChatModelë„ êµ¬í˜„

// ìŠ¤íŠ¸ë¦¬ë°
val flux: Flux<String> = chatModel.stream("Your question")
val content = flux.collectList().block()?.joinToString("")
```

### Prompt

```kotlin
val prompt = Prompt(
    listOf(
        SystemMessage("You are helpful"),
        UserMessage("Your question")
    ),
    ChatOptions.builder()
        .withTemperature(0.7)
        .build()
)
```

---

## 5. Message íƒ€ì…

### UserMessage
ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```kotlin
val userMessage = UserMessage("What is AI?")
```

### SystemMessage
ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```kotlin
val systemMessage = SystemMessage("You are a helpful assistant")
```

### AssistantMessage
AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì´ì „ ì‘ë‹µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```kotlin
val assistantMessage = AssistantMessage("AI stands for...")
```

---

## 6. ChatOptions

```kotlin
val options = ChatOptions.builder()
    .withModel("gpt-4o-mini")
    .withTemperature(0.7)
    .withMaxTokens(500)
    .withTopP(0.9)
    .build()

val prompt = Prompt("Your question", options)
```

### ì£¼ìš” ì˜µì…˜

- **temperature** (0.0-2.0): ì°½ì˜ì„± ì œì–´ (ë†’ì„ìˆ˜ë¡ ì°½ì˜ì )
- **maxTokens**: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
- **topP** (0.0-1.0): Nucleus sampling
- **frequencyPenalty**: ë°˜ë³µ ì–µì œ
- **presencePenalty**: ì£¼ì œ ë‹¤ì–‘ì„±

---

## 7. ChatResponse êµ¬ì¡°

```kotlin
val chatResponse: ChatResponse = chatModel.call(prompt)

// ê²°ê³¼ ì ‘ê·¼
val result: Generation = chatResponse.result
val content: String = result.output.content

// ë©”íƒ€ë°ì´í„°
val metadata: ChatResponseMetadata = chatResponse.metadata
val usage: Usage = metadata.usage
val totalTokens: Int = usage.totalTokens
```

---

## 8. í•™ìŠµ ìˆœì„œ

1. **Sample 01** - ChatModel ê¸°ë³¸ ê°œë…
2. **Sample 02** - ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
3. **Sample 03** - ë©”ì‹œì§€ íƒ€ì…ê³¼ Prompt
4. **Sample 04** - ì˜µì…˜ ì„¤ì •
5. **Sample 05** - ì‘ë‹µ êµ¬ì¡° ì´í•´

---

## 9. ChatModel API ê³„ì¸µ êµ¬ì¡°

```
Model<I, O>
    â”œâ”€â”€ ChatModel
    â”‚   â”œâ”€â”€ call(String): String
    â”‚   â””â”€â”€ call(Prompt): ChatResponse
    â”‚
    â””â”€â”€ StreamingChatModel
        â”œâ”€â”€ stream(String): Flux<String>
        â””â”€â”€ stream(Prompt): Flux<ChatResponse>
```

---

## 10. ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### âœ… ê¶Œì¥ì‚¬í•­

1. **Prompt ê°ì²´ ì‚¬ìš©**
```kotlin
// âœ… ì¢‹ì€ ì˜ˆ
val prompt = Prompt(
    listOf(SystemMessage("..."), UserMessage("...")),
    options
)
val response = chatModel.call(prompt)
```

2. **ì˜µì…˜ ëª…ì‹œ**
```kotlin
// âœ… ëª…í™•í•œ ì˜µì…˜ ì„¤ì •
val options = ChatOptions.builder()
    .withTemperature(0.7)
    .withMaxTokens(500)
    .build()
```

3. **ë©”íƒ€ë°ì´í„° í™œìš©**
```kotlin
// âœ… í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
val usage = chatResponse.metadata.usage
logger.info("Tokens used: ${usage.totalTokens}")
```

### âŒ í”¼í•´ì•¼ í•  íŒ¨í„´

```kotlin
// âŒ ì˜µì…˜ ì—†ì´ ì‚¬ìš©
val response = chatModel.call("question")

// âŒ ë©”íƒ€ë°ì´í„° ë¬´ì‹œ
// í† í° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•˜ì§€ ì•Šìœ¼ë©´ ë¹„ìš© ê´€ë¦¬ ì–´ë ¤ì›€
```

---

## 11. ì°¸ê³  ìë£Œ

- [Spring AI ChatModel ê³µì‹ ë¬¸ì„œ](https://docs.spring.io/spring-ai/reference/api/chatmodel.html)
- [Spring AI Reference](https://docs.spring.io/spring-ai/reference/)
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)

---

**ì‹œì‘í•˜ê¸°**: [Sample 01: Basic ChatModel Usage](./sample01-basic-chatmodel/)
