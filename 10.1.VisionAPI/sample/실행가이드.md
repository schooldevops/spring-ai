# Vision API 샘플 프로젝트 실행 가이드

이 가이드는 Vision API를 활용한 이미지 분석 샘플 프로젝트를 실행하는 방법을 안내합니다.

## 📋 사전 준비사항

### 기본 준비
- JDK 17 이상
- Gradle 설치 (또는 Gradle Wrapper 사용)

### LLM 준비사항

#### OpenAI 사용 시 (권장 - Vision 완전 지원)
- OpenAI API Key 발급: https://platform.openai.com/
- Vision을 지원하는 모델 사용 (GPT-4o, GPT-4 Turbo)

> ⚠️ **중요**: Vision API를 사용하려면 **GPT-4o** 또는 **GPT-4 Turbo** 같은 Vision 지원 모델이 필요합니다. GPT-3.5-turbo는 Vision을 지원하지 않습니다.

#### Anthropic Claude 3 사용 시
- Anthropic API Key 발급: https://console.anthropic.com/
- Claude 3 모델 사용 (Vision 지원)

---

## 🚀 실행 방법

### 시나리오 1: OpenAI GPT-4o 사용 (권장)

#### 1. 환경 변수 설정

```bash
export OPENAI_API_KEY="sk-your-api-key-here"
```

#### 2. application.yml 확인

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4o          # Vision 지원 모델
          temperature: 0.7
          max-tokens: 1000
```

#### 3. 프로젝트 실행

```bash
cd sample
./gradlew bootRun
```

#### 4. 테스트

애플리케이션이 시작되면 다음 엔드포인트를 테스트할 수 있습니다:

```bash
# 상태 확인
curl http://localhost:9000/api/vision/test

# 이미지 분석 (이미지 파일 필요)
curl -X POST http://localhost:9000/api/vision/analyze \
  -F "file=@/path/to/your/image.jpg" \
  -F "question=이 이미지를 설명해주세요"
```

### 시나리오 2: Anthropic Claude 3 사용

#### 1. 환경 변수 설정

```bash
export ANTHROPIC_API_KEY="sk-ant-your-api-key-here"
```

#### 2. build.gradle.kts 수정

```kotlin
dependencies {
    // Anthropic 의존성 주석 해제
    implementation("org.springframework.ai:spring-ai-anthropic-spring-boot-starter:1.0.0-M6")
    
    // OpenAI 의존성 주석 처리
    // implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-M6")
}
```

#### 3. application.yml 수정

```yaml
spring:
  ai:
    anthropic:
      api-key: ${ANTHROPIC_API_KEY}
      chat:
        options:
          model: claude-3-opus-20240229  # Vision 지원 모델
          temperature: 0.7
          max-tokens: 1000
```

#### 4. 프로젝트 재빌드 및 실행

```bash
./gradlew clean build
./gradlew bootRun
```

---

## 🧪 API 엔드포인트 테스트

### 1. 상태 확인

#### GET /api/vision/test

```bash
curl http://localhost:9000/api/vision/test
```

**예상 응답:**
```json
{
  "status": "OK",
  "message": "Vision API is running",
  "endpoints": "...",
  "note": "Vision API를 사용하려면 GPT-4o 또는 Claude 3 등 Vision 지원 모델이 필요합니다."
}
```

### 2. 이미지 분석

#### POST /api/vision/analyze

```bash
curl -X POST http://localhost:9000/api/vision/analyze \
  -F "file=@/path/to/image.jpg" \
  -F "question=이 이미지를 자세히 설명해주세요"
```

**예상 응답:**
```json
{
  "success": true,
  "question": "이 이미지를 자세히 설명해주세요",
  "description": "이 이미지는...",
  "filename": "image.jpg",
  "size": 123456,
  "contentType": "image/jpeg"
}
```

### 3. 이미지 설명 생성

#### POST /api/vision/describe

```bash
curl -X POST http://localhost:9000/api/vision/describe \
  -F "file=@/path/to/image.jpg"
```

**예상 응답:**
```json
{
  "success": true,
  "description": "이 이미지는...",
  "filename": "image.jpg",
  "size": 123456
}
```

### 4. 이미지에 대한 질문

#### POST /api/vision/ask

```bash
curl -X POST http://localhost:9000/api/vision/ask \
  -F "file=@/path/to/image.jpg" \
  -F "question=이 이미지에 있는 사람은 몇 명인가요?"
```

**예상 응답:**
```json
{
  "success": true,
  "question": "이 이미지에 있는 사람은 몇 명인가요?",
  "answer": "이 이미지에는 3명의 사람이 있습니다.",
  "filename": "image.jpg"
}
```

### 5. 이미지 상세 분석

#### POST /api/vision/analyze-details

```bash
curl -X POST http://localhost:9000/api/vision/analyze-details \
  -F "file=@/path/to/image.jpg"
```

**예상 응답:**
```json
{
  "success": true,
  "analysis": "1. 주요 객체들: ...\n2. 주요 색상: ...\n3. 이미지 스타일: ...",
  "filename": "image.jpg",
  "size": 123456
}
```

---

## 📊 Postman Collection

Postman을 사용하는 경우:

### Request 1: 상태 확인
- Method: GET
- URL: `http://localhost:9000/api/vision/test`

### Request 2: 이미지 분석
- Method: POST
- URL: `http://localhost:9000/api/vision/analyze`
- Body: form-data
  - `file`: (File) 이미지 파일 선택
  - `question`: (Text) "이 이미지를 설명해주세요"

### Request 3: 이미지 설명
- Method: POST
- URL: `http://localhost:9000/api/vision/describe`
- Body: form-data
  - `file`: (File) 이미지 파일 선택

---

## 🔍 확인 사항

### OpenAI 확인

```bash
# 환경 변수 확인
echo $OPENAI_API_KEY

# API 테스트
curl http://localhost:9000/api/vision/test
```

### Anthropic 확인

```bash
# 환경 변수 확인
echo $ANTHROPIC_API_KEY

# API 테스트
curl http://localhost:9000/api/vision/test
```

---

## ❌ 문제 해결

### 문제 1: Vision API가 작동하지 않음

**증상**: 이미지를 분석하지 못함

**원인**:
- Vision을 지원하지 않는 모델 사용 (예: GPT-3.5-turbo)
- Spring AI 1.0.0-M6에서 Vision API가 완전히 지원되지 않을 수 있음

**해결책**:
- GPT-4o 또는 GPT-4 Turbo 사용
- Claude 3 사용
- 모델별 Vision API 문서 확인

### 문제 2: 이미지 업로드 실패

**증상**: 이미지 업로드 시 오류 발생

**원인**:
- 이미지 크기가 너무 큼
- 지원하지 않는 이미지 형식

**해결책**:
- 이미지 크기 확인 (일반적으로 20MB 이하)
- 지원하는 형식 사용 (PNG, JPEG, GIF, WebP)

### 문제 3: OpenAI API Key 오류

**증상**:
```
Invalid API Key
```

**해결책**:
```bash
# 환경 변수 확인
echo $OPENAI_API_KEY

# 올바른 키 설정
export OPENAI_API_KEY="sk-..."
```

---

## ⚠️ 중요 사항

### Spring AI 1.0.0-M6의 Vision API 지원

Spring AI 1.0.0-M6에서는 Vision API가 아직 완전히 지원되지 않을 수 있습니다. 이 샘플 프로젝트는:

1. **Vision API 사용 패턴**을 보여줍니다
2. **이미지를 Base64로 인코딩**하여 전송하는 방식을 사용합니다
3. **실제 Vision API 사용**은 모델별로 다를 수 있습니다

### 실제 Vision API 사용

실제 Vision API를 사용하려면:
- 모델별 공식 문서 참고
- 최신 Spring AI 버전 확인
- 모델별 Vision API 구현 방식 확인

---

## ✅ 체크리스트

실행 전 확인:

### 기본
- [ ] JDK 17 이상 설치됨
- [ ] 프로젝트 빌드 성공 (`./gradlew build`)
- [ ] 애플리케이션 실행 성공

### OpenAI 사용 시
- [ ] OpenAI API Key 발급됨
- [ ] 환경 변수 설정됨 (`export OPENAI_API_KEY`)
- [ ] GPT-4o 또는 GPT-4 Turbo 모델 사용
- [ ] API 엔드포인트 응답 확인

### Anthropic 사용 시
- [ ] Anthropic API Key 발급됨
- [ ] 환경 변수 설정됨 (`export ANTHROPIC_API_KEY`)
- [ ] Claude 3 모델 사용
- [ ] API 엔드포인트 응답 확인

---

## 🎓 학습 시나리오

### 단계 1: 기본 이미지 분석
1. `/api/vision/analyze` 엔드포인트 테스트
2. 이미지 업로드 및 분석 결과 확인
3. 응답 형식 이해

### 단계 2: 이미지 설명 생성
1. `/api/vision/describe` 엔드포인트 테스트
2. 자동 이미지 설명 생성 확인

### 단계 3: 이미지 질문
1. `/api/vision/ask` 엔드포인트 테스트
2. 이미지에 대한 질문에 답변 확인

### 단계 4: 코드 분석
1. `VisionService.kt` 확인 - 이미지 분석 로직
2. `VisionController.kt` 확인 - API 엔드포인트 구현
3. Base64 인코딩 방식 이해

---

## 📚 다음 단계

이 샘플 프로젝트를 성공적으로 실행했다면:

1. ✅ Vision API의 기본 개념을 이해했습니다
2. ✅ 이미지를 Base64로 인코딩하여 전송하는 방법을 배웠습니다
3. ✅ 이미지 분석, 설명 생성, 질문 답변 기능을 구현했습니다
4. ✅ 다음 장으로 진행할 준비가 되었습니다!

**다음 학습**: [10.2: 이미지 업로드 및 분석](../../README.md#102-이미지-업로드-및-분석)

---

## 💡 추가 학습 자료

- [Spring AI Multimodality 공식 문서](https://docs.spring.io/spring-ai/reference/api/multimodal.html)
- [OpenAI Vision API 가이드](https://platform.openai.com/docs/guides/vision)
- [Anthropic Claude Vision 가이드](https://docs.anthropic.com/claude/docs/vision)

